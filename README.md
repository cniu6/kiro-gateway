<div align="center">

# üëª Kiro Gateway

**Proxy gateway for Kiro API (AWS CodeWhisperer)**

Made with ‚ù§Ô∏è by [@Jwadow](https://github.com/jwadow)

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)

*Use Claude models through any OpenAI or Anthropic compatible tool*

[Features](#-features) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Configuration](#%EF%B8%8F-configuration) ‚Ä¢ [API Reference](#-api-reference) ‚Ä¢ [License](#-license)

</div>

---

## ‚ú® Features

| Feature | Description |
|---------|-------------|
| üîå **OpenAI-compatible API** | Works with any OpenAI-compatible tool |
| üîå **Anthropic-compatible API** | Native `/v1/messages` endpoint |
| üñ±Ô∏è **Cursor IDE Support** | Full compatibility with Cursor's tool format |
| ü§ñ **Claude Code Support** | Full compatibility with Claude Code CLI |
| üß† **Extended Thinking** | See how the model reasons before answering |
| üí¨ **Full message history** | Passes complete conversation context |
| üõ†Ô∏è **Tool Calling** | Supports function calling (OpenAI & Anthropic formats) |
| üì° **Streaming** | Full SSE streaming support |
| üîÑ **Retry Logic** | Automatic retries on errors (403, 429, 5xx) |
| üìã **Extended model list** | Including versioned models |
| üîê **Smart token management** | Automatic refresh before expiration |

---

## üöÄ Quick Start

### Prerequisites

- Python 3.10+
- One of the following:
  - [Kiro IDE](https://kiro.dev/) with logged in account, OR
  - [Kiro CLI](https://kiro.dev/cli/) with AWS SSO (Builder ID)

### Installation

```bash
# Clone the repository
git clone https://github.com/Jwadow/kiro-gateway.git
cd kiro-gateway

# Install dependencies
pip install -r requirements.txt

# Configure (see Configuration section)
cp .env.example .env
# Copy and edit .env with your credentials

# Start the server
python main.py

# Or with custom port (if 8000 is busy)
python main.py --port 9000
```

The server will be available at `http://localhost:8000`

---

## ‚öôÔ∏è Configuration

### Option 1: JSON Credentials File

Specify the path to the credentials file:

```env
KIRO_CREDS_FILE="~/.aws/sso/cache/kiro-auth-token.json"

# Password to protect YOUR proxy server (make up any secure string)
# You'll use this as api_key when connecting to your gateway
PROXY_API_KEY="my-super-secret-password-123"
```

<details>
<summary>üìÑ JSON file format</summary>

```json
{
  "accessToken": "eyJ...",
  "refreshToken": "eyJ...",
  "expiresAt": "2025-01-12T23:00:00.000Z",
  "profileArn": "arn:aws:codewhisperer:us-east-1:...",
  "region": "us-east-1"
}
```

</details>

### Option 2: Environment Variables (.env file)

Create a `.env` file in the project root:

```env
# Required
REFRESH_TOKEN="your_kiro_refresh_token"

# Password to protect YOUR proxy server (make up any secure string)
PROXY_API_KEY="my-super-secret-password-123"

# Optional
PROFILE_ARN="arn:aws:codewhisperer:us-east-1:..."
KIRO_REGION="us-east-1"
```

### Option 3: AWS SSO Credentials (kiro-cli)

If you use `kiro-cli` with AWS IAM Identity Center (SSO), the gateway will automatically detect and use AWS SSO OIDC authentication.

```env
KIRO_CREDS_FILE="~/.aws/sso/cache/your-sso-cache-file.json"

# Password to protect YOUR proxy server
PROXY_API_KEY="my-super-secret-password-123"

# Note: PROFILE_ARN is NOT needed for AWS SSO OIDC (Builder ID) users
# The gateway will work without it
```

<details>
<summary>üìÑ AWS SSO JSON file format</summary>

AWS SSO credentials files (from `~/.aws/sso/cache/`) contain:

```json
{
  "accessToken": "eyJ...",
  "refreshToken": "eyJ...",
  "expiresAt": "2025-01-12T23:00:00.000Z",
  "region": "us-east-1",
  "clientId": "...",
  "clientSecret": "..."
}
```

**Note:** AWS SSO OIDC (Builder ID) users do NOT need `profileArn`. The gateway will work without it (if specified, it will be ignored).

</details>

<details>
<summary>üîç How it works</summary>

The gateway automatically detects the authentication type based on the credentials file:

- **Kiro Desktop Auth** (default): Used when `clientId` and `clientSecret` are NOT present
  - Endpoint: `https://prod.{region}.auth.desktop.kiro.dev/refreshToken`
  
- **AWS SSO OIDC**: Used when `clientId` and `clientSecret` ARE present
  - Endpoint: `https://oidc.{region}.amazonaws.com/token`

No additional configuration is needed ‚Äî just point to your credentials file!

</details>

### Option 4: kiro-cli SQLite Database

If you use `kiro-cli` and prefer to use its SQLite database directly:

```env
KIRO_CLI_DB_FILE="~/.local/share/kiro-cli/data.sqlite3"

# Password to protect YOUR proxy server
PROXY_API_KEY="my-super-secret-password-123"

# Note: PROFILE_ARN is NOT needed for AWS SSO OIDC (Builder ID) users
# The gateway will work without it
```

<details>
<summary>üìÑ Database locations</summary>

| CLI Tool | Database Path |
|----------|---------------|
| kiro-cli | `~/.local/share/kiro-cli/data.sqlite3` |
| amazon-q-developer-cli | `~/.local/share/amazon-q/data.sqlite3` |

The gateway reads credentials from the `auth_kv` table which stores:
- `kirocli:odic:token` or `codewhisperer:odic:token` ‚Äî access token, refresh token, expiration
- `kirocli:odic:device-registration` or `codewhisperer:odic:device-registration` ‚Äî client ID and secret

Both key formats are supported for compatibility with different kiro-cli versions.

</details>

### Getting Credentials

**For Kiro IDE users:**
- Log in to Kiro IDE and use Option 1 above (JSON credentials file)
- The credentials file is created automatically after login

**For Kiro CLI users:**
- Log in with `kiro-cli login` and use Option 3 or Option 4 above
- No manual token extraction needed!

<details>
<summary>üîß Advanced: Manual token extraction</summary>

If you need to manually extract the refresh token (e.g., for debugging), you can intercept Kiro IDE traffic:
- Look for requests to: `prod.us-east-1.auth.desktop.kiro.dev/refreshToken`

</details>

---

## üñ±Ô∏è Cursor IDE Support

Kiro Gateway fully supports Cursor IDE out of the box. No special configuration needed.

### Configuration in Cursor

1. Open Cursor Settings ‚Üí Models ‚Üí Add Model
2. Configure:
   - **API Base URL**: `http://localhost:8000/v1`
   - **API Key**: Your `PROXY_API_KEY` from `.env`
   - **Model**: `claude-sonnet-4-5` (or any available model)

### How It Works

Cursor uses a slightly different API format than standard OpenAI:

| Feature | OpenAI Format | Cursor Format |
|---------|---------------|---------------|
| Tool Definition | `{type: "function", function: {...}}` | `{name, description, input_schema}` |
| Tool Calls | `tool_calls` field | `content[type="tool_use"]` |
| Tool Results | `role: "tool"` message | `content[type="tool_result"]` |

The gateway automatically detects and handles both formats transparently.

<details>
<summary>üîß Technical Details</summary>

The gateway performs the following conversions:

1. **Tool Definitions**: Accepts both nested OpenAI format and flat Cursor format
2. **Tool Calls**: Extracts from both `tool_calls` field and `content` array
3. **Tool Results**: Converts `tool_use_id` to `toolUseId` for Kiro API
4. **JSON Schema**: Sanitizes unsupported fields (`anyOf`, `title`, `default`, etc.)

See [docs/CURSOR_SUPPORT_IMPLEMENTATION.md](docs/CURSOR_SUPPORT_IMPLEMENTATION.md) for full implementation details.

</details>

---

## ü§ñ Claude Code Support

Kiro Gateway fully supports [Claude Code](https://docs.anthropic.com/en/docs/claude-code) (Anthropic's official CLI).

### Configuration

```bash
# Set Claude Code to use your gateway
claude config set --global apiUrl http://localhost:8000
claude config set --global apiKey your-proxy-api-key
```

### How It Works

Claude Code uses the Anthropic Messages API (`/v1/messages`) with some extended features:

| Feature | Standard Anthropic | Claude Code |
|---------|-------------------|-------------|
| System Prompt | `"system": "string"` | `"system": [{"type": "text", "text": "...", "cache_control": {...}}]` |
| Cache Control | Not used | `{"type": "ephemeral"}` on content blocks |

The gateway automatically handles both formats:

1. **String format**: Standard Anthropic API ‚Äî passed through as-is
2. **Array format**: Claude Code style ‚Äî text blocks are extracted and joined

<details>
<summary>üîß Technical Details</summary>

Claude Code sends system prompts as an array of content blocks with `cache_control`:

```json
{
  "system": [
    {"type": "text", "text": "You are Claude Code...", "cache_control": {"type": "ephemeral"}},
    {"type": "text", "text": "Additional instructions...", "cache_control": {"type": "ephemeral"}}
  ]
}
```

The gateway converts this to a plain string by:
1. Extracting `text` from each block with `type: "text"`
2. Joining them with newlines
3. Ignoring `cache_control` (not supported by Kiro API)

This conversion happens in `converters_anthropic.py`:

```python
def convert_system_prompt(system: Optional[SystemPrompt]) -> str:
    if isinstance(system, list):
        text_parts = [block.get("text", "") for block in system if block.get("type") == "text"]
        return "\n".join(text_parts)
    return system or ""
```

</details>

---

## üì° API Reference

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Health check |
| `/health` | GET | Detailed health check |
| `/v1/models` | GET | List available models |
| `/v1/chat/completions` | POST | OpenAI Chat Completions API |
| `/v1/messages` | POST | Anthropic Messages API |

### Available Models

| Model | Description |
|-------|-------------|
| `claude-opus-4-5` | Top-tier model |
| `claude-opus-4-5-20251101` | Top-tier model (versioned) |
| `claude-sonnet-4-5` | Enhanced model |
| `claude-sonnet-4-5-20250929` | Enhanced model (versioned) |
| `claude-sonnet-4` | Balanced model |
| `claude-sonnet-4-20250514` | Balanced model (versioned) |
| `claude-haiku-4-5` | Fast model |
| `claude-3-7-sonnet-20250219` | Legacy model |

---

## üí° Usage Examples

### OpenAI API

<details>
<summary>üîπ Simple cURL Request</summary>

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Authorization: Bearer my-super-secret-password-123" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "messages": [{"role": "user", "content": "Hello!"}],
    "stream": true
  }'
```

> **Note:** Replace `my-super-secret-password-123` with the `PROXY_API_KEY` you set in your `.env` file.

</details>

<details>
<summary>üîπ Streaming Request</summary>

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Authorization: Bearer my-super-secret-password-123" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is 2+2?"}
    ],
    "stream": true
  }'
```

</details>

<details>
<summary>üõ†Ô∏è With Tool Calling</summary>

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Authorization: Bearer my-super-secret-password-123" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "messages": [{"role": "user", "content": "What is the weather in London?"}],
    "tools": [{
      "type": "function",
      "function": {
        "name": "get_weather",
        "description": "Get weather for a location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {"type": "string", "description": "City name"}
          },
          "required": ["location"]
        }
      }
    }]
  }'
```

</details>

<details>
<summary>üêç Python OpenAI SDK</summary>

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="my-super-secret-password-123"  # Your PROXY_API_KEY from .env
)

response = client.chat.completions.create(
    model="claude-sonnet-4-5",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ],
    stream=True
)

for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

</details>

<details>
<summary>ü¶ú LangChain</summary>

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    base_url="http://localhost:8000/v1",
    api_key="my-super-secret-password-123",  # Your PROXY_API_KEY from .env
    model="claude-sonnet-4-5"
)

response = llm.invoke("Hello, how are you?")
print(response.content)
```

</details>

### Anthropic API

<details>
<summary>üîπ Simple cURL Request</summary>

```bash
curl http://localhost:8000/v1/messages \
  -H "x-api-key: my-super-secret-password-123" \
  -H "anthropic-version: 2023-06-01" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "max_tokens": 1024,
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

> **Note:** Anthropic API uses `x-api-key` header instead of `Authorization: Bearer`. Both are supported.

</details>

<details>
<summary>üîπ With System Prompt</summary>

```bash
curl http://localhost:8000/v1/messages \
  -H "x-api-key: my-super-secret-password-123" \
  -H "anthropic-version: 2023-06-01" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "max_tokens": 1024,
    "system": "You are a helpful assistant.",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

> **Note:** In Anthropic API, `system` is a separate field, not a message.

</details>

<details>
<summary>üì° Streaming</summary>

```bash
curl http://localhost:8000/v1/messages \
  -H "x-api-key: my-super-secret-password-123" \
  -H "anthropic-version: 2023-06-01" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "max_tokens": 1024,
    "stream": true,
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

</details>

<details>
<summary>üêç Python Anthropic SDK</summary>

```python
import anthropic

client = anthropic.Anthropic(
    api_key="my-super-secret-password-123",  # Your PROXY_API_KEY from .env
    base_url="http://localhost:8000"
)

# Non-streaming
response = client.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=1024,
    messages=[{"role": "user", "content": "Hello!"}]
)
print(response.content[0].text)

# Streaming
with client.messages.stream(
    model="claude-sonnet-4-5",
    max_tokens=1024,
    messages=[{"role": "user", "content": "Hello!"}]
) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)
```

</details>

---

## üîß Debugging

Debug logging is **disabled by default**. To enable, add to your `.env`:

```env
# Debug logging mode:
# - off: disabled (default)
# - errors: save logs only for failed requests (4xx, 5xx) - recommended for troubleshooting
# - all: save logs for every request (overwrites on each request)
DEBUG_MODE=errors
```

### Debug Modes

| Mode | Description | Use Case |
|------|-------------|----------|
| `off` | Disabled (default) | Production |
| `errors` | Save logs only for failed requests (4xx, 5xx) | **Recommended for troubleshooting** |
| `all` | Save logs for every request | Development/debugging |

### Debug Files

When enabled, requests are logged to the `debug_logs/` folder:

| File | Description |
|------|-------------|
| `request_body.json` | Incoming request from client (OpenAI format) |
| `kiro_request_body.json` | Request sent to Kiro API |
| `response_stream_raw.txt` | Raw stream from Kiro |
| `response_stream_modified.txt` | Transformed stream (OpenAI format) |
| `app_logs.txt` | Application logs for the request |
| `error_info.json` | Error details (only on errors) |

---

## üìú License

This project is licensed under the **GNU Affero General Public License v3.0 (AGPL-3.0)**.

This means:
- ‚úÖ You can use, modify, and distribute this software
- ‚úÖ You can use it for commercial purposes
- ‚ö†Ô∏è **You must disclose source code** when you distribute the software
- ‚ö†Ô∏è **Network use is distribution** ‚Äî if you run a modified version on a server and let others interact with it, you must make the source code available to them
- ‚ö†Ô∏è Modifications must be released under the same license

See the [LICENSE](LICENSE) file for the full license text.

### Why AGPL-3.0?

AGPL-3.0 ensures that improvements to this software benefit the entire community. If you modify this gateway and deploy it as a service, you must share your improvements with your users.

### Contributor License Agreement (CLA)

By submitting a contribution to this project, you agree to the terms of our [Contributor License Agreement (CLA)](CLA.md). This ensures that:
- You have the right to submit the contribution
- You grant the maintainer rights to use and relicense your contribution
- The project remains legally protected

---

## üíñ Support the Project

<div align="center">

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Smilies/Smiling%20Face%20with%20Hearts.png" alt="Love" width="80" />

**If this project saved you time or money, consider supporting it!**

Every contribution helps keep this project alive and growing

<br>

### ü§ë Donate

[**‚òï One-time Donation**](https://app.lava.top/jwadow?tabId=donate) &nbsp;‚Ä¢&nbsp; [**üíé Monthly Support**](https://app.lava.top/jwadow?tabId=subscriptions)

<br>

### ü™ô Or send crypto

| Currency | Network | Address |
|:--------:|:-------:|:--------|
| **USDT** | TRC20 | `TSVtgRc9pkC1UgcbVeijBHjFmpkYHDRu26` |
| **BTC** | Bitcoin | `12GZqxqpcBsqJ4Vf1YreLqwoMGvzBPgJq6` |
| **ETH** | Ethereum | `0xc86eab3bba3bbaf4eb5b5fff8586f1460f1fd395` |
| **SOL** | Solana | `9amykF7KibZmdaw66a1oqYJyi75fRqgdsqnG66AK3jvh` |
| **TON** | TON | `UQBVh8T1H3GI7gd7b-_PPNnxHYYxptrcCVf3qQk5v41h3QTM` |

</div>

---

## ‚ö†Ô∏è Disclaimer

This project is not affiliated with, endorsed by, or sponsored by Amazon Web Services (AWS), Anthropic, or Kiro IDE. Use at your own risk and in compliance with the terms of service of the underlying APIs.

---

<div align="center">

**[‚¨Ü Back to Top](#-kiro-gateway)**

</div>
